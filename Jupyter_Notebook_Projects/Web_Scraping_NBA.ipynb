{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Web_Scraping_NBA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7pcKGPEGixnKR5j72aEpI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-MSilva/Predict-NBA-player-Points-End-to-end-Project/blob/master/Jupyter_Notebook_Projects/Web_Scraping_NBA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_Mgi07RfoWC"
      },
      "source": [
        "# Scraping nbastuffer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5za5gHpyfoWD"
      },
      "source": [
        "## 1 - Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipyMFcOdfoWD"
      },
      "outputs": [],
      "source": [
        "import requests #To make the request to the site\n",
        "from bs4 import BeautifulSoup as Bfs #to collect data from an HTML or XML\n",
        "import pandas as pd #To organize and rearrange the tables\n",
        "import numpy as np #To manipulate lists"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojGzOpr4ggs0"
      },
      "source": [
        "##  2 - Get the link of stats of the players"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axsNRnkI5V4e"
      },
      "source": [
        "In this part of the code we collect the links from the tables, which have information about the athletes and store them in a list."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getLinks(): \n",
        "  headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
        "\n",
        "  #collect all links\n",
        "  links=[]\n",
        "\n",
        "  #get the page url\n",
        "  URL = 'https://www.nbastuffer.com/player-stats/'\n",
        "\n",
        "  #access the site\n",
        "  issue = requests.get(URL, headers=headers)\n",
        "\n",
        "  #extract the information\n",
        "  Web = Bfs(issue.content, 'html.parser')\n",
        "\n",
        "  #We look for tags of interest\n",
        "  players = Web.findAll('div', attrs={'class': 'entry-wrap'})\n",
        "\n",
        "\n",
        "  for item in players:\n",
        "    atag = item.a #we use the link tag\n",
        "    link_aux = atag.get('href')\n",
        "    if link_aux == 'https://www.nbastuffer.com/2017-nba-playoffs-player-stats/':\n",
        "        break  \n",
        "    if link_aux:\n",
        "      links.append(link_aux)#and we put on the list\n",
        "  return(links)"
      ],
      "metadata": {
        "id": "uK7XENfRkak0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuezfNk4uByQ"
      },
      "source": [
        "## 3 - Search athletes automatically and avoid errors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZ3GtRips-qv"
      },
      "source": [
        "First, we search the table for the tags that give us your information. We use try, except in cases where we can't find the athlete's information on the site, and when that happens, if it's not points, we assign an empty string to the variable."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def search_auto(athlet_dict,athletes):\n",
        "\n",
        "  #we count the maximum number of players in the table\n",
        "  number_of_rows = len(athletes.findAll(lambda tag: tag.name == 'tr')) + 1\n",
        "\n",
        "  #we take all the lines we are interested in\n",
        "  for i in range(2,number_of_rows):\n",
        "    if(i%2==0):\n",
        "      row = 'row-{}'.format(i) + ' even'\n",
        "    else:\n",
        "      row = 'row-{}'.format(i) + ' odd'\n",
        "\n",
        "    #if we don't find the line we want, we exit the loop\n",
        "    aux = athletes.find('tr', attrs={'class': row})\n",
        "    if(aux == 'None'):\n",
        "      break\n",
        "  \n",
        "    #as the player's score is the most important variable, if we don't find such a tag we exit the function\n",
        "    try:\n",
        "      athlet_dict['PPG'].append(aux.find('td', attrs={'class': 'column-19'}).text)\n",
        "    except AttributeError:\n",
        "      return\n",
        "\n",
        "    #for all tags we look for them, and if we don't find them we put empty in the string\n",
        "    try:\n",
        "      athlet_dict['TEAM'].append(aux.find('td', attrs={'class': 'column-3'}).text)\n",
        "    except AttributeError:\n",
        "      athlet_dict['TEAM'].append('')\n",
        "\n",
        "    try:\n",
        "      athlet_dict['POS'].append(aux.find('td', attrs={'class': 'column-4'}).text)\n",
        "    except AttributeError:\n",
        "      athlet_dict['POS'].append('')\n",
        "\n",
        "    \n",
        "    try:\n",
        "      athlet_dict['AGE'].append(aux.find('td', attrs={'class': 'column-5'}).text)\n",
        "    except AttributeError:\n",
        "      athlet_dict['AGE'].append('')\n",
        "\n",
        "    try:\n",
        "      athlet_dict['GP'].append(aux.find('td', attrs={'class': 'column-6'}).text)\n",
        "    except AttributeError:\n",
        "      athlet_dict['GP'].append('')\n",
        "\n",
        "    try:\n",
        "      athlet_dict['MPG'].append(aux.find('td', attrs={'class': 'column-7'}).text)\n",
        "    except AttributeError:\n",
        "      athlet_dict['MPG'].append('')\n",
        "    \n",
        "    try:\n",
        "      athlet_dict['MIN%'].append(aux.find('td', attrs={'class': 'column-8'}).text)\n",
        "    except AttributeError:\n",
        "      athlet_dict['MIN%'].append('')\n",
        "\n",
        "    try:\n",
        "      athlet_dict['USG%'].append(aux.find('td', attrs={'class': 'column-9'}).text)\n",
        "    except AttributeError:\n",
        "      athlet_dict['USG%'].append('')\n",
        "\n",
        "    try:\n",
        "      athlet_dict['TO%'].append(aux.find('td', attrs={'class': 'column-10'}).text)\n",
        "    except AttributeError:\n",
        "      athlet_dict['TO%'].append('')\n",
        "  \n",
        "    try:\n",
        "      athlet_dict['FTA'].append(aux.find('td', attrs={'class': 'column-11'}).text)\n",
        "    except AttributeError:\n",
        "      athlet_dict['FTA'].append('')\n",
        "\n",
        "\n",
        "    try:\n",
        "      athlet_dict['FT%'].append(aux.find('td', attrs={'class': 'column-12'}).text)\n",
        "    except AttributeError:\n",
        "      athlet_dict['FT%'].append('')\n",
        "\n",
        "    try:\n",
        "      athlet_dict['2PA'].append(aux.find('td', attrs={'class': 'column-13'}).text)\n",
        "    except AttributeError:\n",
        "      athlet_dict['2PA'].append('')\n",
        "\n",
        "    try:\n",
        "      athlet_dict['3PA'].append(aux.find('td', attrs={'class': 'column-15'}).text)\n",
        "    except AttributeError:\n",
        "      athlet_dict['3PA'].append('')\n",
        "\n",
        "    try:\n",
        "      athlet_dict['FULL NAME'].append(aux.find('td', attrs={'class': 'column-2'}).text)\n",
        "    except AttributeError:\n",
        "      athlet_dict['FULL NAME'].append('')\n",
        "\n",
        "    try:\n",
        "      athlet_dict['RPG'].append(aux.find('td', attrs={'class': 'column-20'}).text)\n",
        "    except AttributeError:\n",
        "      athlet_dict['RPG'].append('')\n",
        "\n",
        "    try:\n",
        "      athlet_dict['TRB%'].append(aux.find('td', attrs={'class': 'column-21'}).text)\n",
        "    except AttributeError:\n",
        "      athlet_dict['TRB%'].append('')\n",
        "\n",
        "    try:\n",
        "      athlet_dict['APG'].append(aux.find('td', attrs={'class': 'column-22'}).text)\n",
        "    except AttributeError:\n",
        "      athlet_dict['APG'].append('')\n",
        "\n",
        "\n",
        "    try:\n",
        "      athlet_dict['SPG'].append(aux.find('td', attrs={'class': 'column-24'}).text)\n",
        "    except AttributeError:\n",
        "      athlet_dict['SPG'].append('')\n",
        "\n",
        "\n",
        "    try:\n",
        "      athlet_dict['BPG'].append(aux.find('td', attrs={'class': 'column-25'}).text)\n",
        "    except AttributeError:\n",
        "      athlet_dict['BPG'].append('')\n",
        "\n",
        "    try:\n",
        "      athlet_dict['TOPG'].append(aux.find('td', attrs={'class': 'column-26'}).text)\n",
        "    except AttributeError:\n",
        "      athlet_dict['TOPG'].append('')\n",
        "\n",
        "\n",
        "  return athlet_dict"
      ],
      "metadata": {
        "id": "i53O4Xx3vo6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOYpF3Y-7cqN"
      },
      "source": [
        "##  4 - Collect all data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nnGtO5V7Ky9"
      },
      "source": [
        "We do the same thing as before with the links of the tables, only now we get all the precious information of the athlete in each table that is on the site."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "def CollectAlldata():\n",
        "\n",
        "  #first we get all links,\n",
        "  links = getLinks()\n",
        "\n",
        "  #we create a dictionary with several lists for each column of the table that we will collect.\n",
        "  player_dict = {'FULL NAME':[], 'TEAM':[],'POS':[],'AGE':[],'GP':[],'MPG':[],'MIN%':[],'USG%':[]\n",
        "               ,'TO%':[],'FTA':[],'FT%':[],'2PA':[],'3PA':[],'PPG':[],'RPG':[],'TRB%':[],'APG':[]\n",
        "               ,'SPG':[],'BPG':[],'TOPG':[]}\n",
        "\n",
        "  #Default website header.\n",
        "  headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
        "  \n",
        "  #we travel the links in the list\n",
        "  for intem_links in links:\n",
        "  \n",
        "    #access the site\n",
        "    issue = requests.get(intem_links, headers=headers)\n",
        "\n",
        "    #extract the information\n",
        "    Web = Bfs(issue.content, 'html.parser')\n",
        "\n",
        "\n",
        "    #we select the tag that contains all the information we need\n",
        "    athletes = Web.find('div', attrs={'class': 'tablepress-scroll-wrapper'})\n",
        "    \n",
        "    #if everything is correct we collect all the tags we insert them in a dictionary, and finally in a dataframe created\n",
        "    if athletes:\n",
        "      result = search_auto(player_dict,athletes)\n",
        "      DataFrame = pd.DataFrame(result)\n",
        "  \n",
        "  DataFrame.to_csv('NBA_Athletes.csv',line_terminator='',encoding='utf-8')"
      ],
      "metadata": {
        "id": "mgxYiBbPmysd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  CollectAlldata()"
      ],
      "metadata": {
        "id": "xN32oTL7pEkz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}